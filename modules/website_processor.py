"""
Processeur de sites web unifi√© - Int√©gration Firecrawl dans l'architecture existante
Remplace l'ancien LLM processor avec des capacit√©s avanc√©es
"""

import asyncio
import os
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict

from .firecrawl_extractor import FirecrawlExtractor, FirecrawlConfig, extract_hotels_with_firecrawl
# üî• FIRECRAWL ONLY - Plus de Legacy imports


@dataclass 
class WebsiteProcessorConfig:
    """Configuration du processeur de sites web"""
    use_firecrawl: bool = True
    firecrawl_api_key: str = ""
    fallback_to_legacy: bool = False  # üî• FIRECRAWL ONLY
    max_concurrent_extractions: int = 3
    batch_size: int = 8
    timeout: int = 120
    
    @classmethod
    def from_env(cls):
        """Cr√©e la configuration depuis les variables d'environnement"""
        return cls(
            use_firecrawl=True,  # üîß R√©activer Firecrawl pour debug NoneType
            firecrawl_api_key=os.getenv('FIRECRAWL_API_KEY', ''),
            fallback_to_legacy=False,  # üîß D√©sactiver Legacy pour forcer Firecrawl
            max_concurrent_extractions=int(os.getenv('MAX_CONCURRENT_EXTRACTIONS', '3')),
            batch_size=int(os.getenv('FIRECRAWL_BATCH_SIZE', '8')),
            timeout=int(os.getenv('FIRECRAWL_TIMEOUT', '120'))
        )


class WebsiteProcessor:
    """Processeur unifi√© pour l'extraction de donn√©es de sites web d'h√¥tels
    
    Utilise Firecrawl en priorit√© avec fallback sur l'ancien syst√®me LLM
    """
    
    def __init__(self, config: WebsiteProcessorConfig = None):
        self.config = config or WebsiteProcessorConfig.from_env()
        
        # Initialiser Firecrawl si disponible
        self.firecrawl_extractor = None
        if self.config.use_firecrawl and self.config.firecrawl_api_key:
            try:
                firecrawl_config = FirecrawlConfig(
                    api_key=self.config.firecrawl_api_key,
                    rate_limit_requests_per_minute=100,  # Plan payant
                    rate_limit_wait_seconds=1,  # S√©curit√© 1s
                    timeout=self.config.timeout
                )
                self.firecrawl_available = True
                print("üî• Firecrawl configur√© et pr√™t")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur configuration Firecrawl: {e}")
                self.firecrawl_available = False
        else:
            self.firecrawl_available = False
            print("üìù Firecrawl non disponible - utilisation Legacy LLM")
        
        # Legacy supprim√© - Firecrawl uniquement
        self.legacy_available = False
        
        # Statistiques
        self.stats = {
            'total_processed': 0,
            'firecrawl_success': 0,
            'legacy_fallback': 0,
            'total_failures': 0,
            'processing_start': None
        }
    
    async def process_hotels_websites(self, hotels_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Traite les sites web d'une liste d'h√¥tels
        
        Args:
            hotels_data: Liste de dictionnaires avec name, address, website_url ou url
            
        Returns:
            Liste des r√©sultats de traitement
        """
        
        print(f"üåê D√©but traitement sites web pour {len(hotels_data)} h√¥tels")
        self.stats['processing_start'] = datetime.now()
        self.stats['total_processed'] = len(hotels_data)
        
        # Normaliser les donn√©es d'entr√©e
        normalized_hotels = self._normalize_hotel_data(hotels_data)
        
        # S√©parer les h√¥tels avec/sans URL
        hotels_with_urls = [h for h in normalized_hotels if h.get('website_url')]
        hotels_without_urls = [h for h in normalized_hotels if not h.get('website_url')]
        
        print(f"üìä {len(hotels_with_urls)} h√¥tels avec URL, {len(hotels_without_urls)} sans URL")
        
        results = []
        
        # Traiter les h√¥tels avec URLs
        if hotels_with_urls:
            if self.firecrawl_available and self.config.use_firecrawl:
                print("üî• Utilisation Firecrawl pour extraction")
                firecrawl_results = await self._process_with_firecrawl(hotels_with_urls)
                results.extend(firecrawl_results)
            elif self.legacy_available:
                print("üîÑ Utilisation Legacy pour extraction (temporaire)")
                legacy_results = await self._process_with_legacy(hotels_with_urls)
                results.extend(legacy_results)
            else:
                print("‚ùå Aucun processeur disponible")
                for hotel in hotels_with_urls:
                    results.append(self._create_failure_result(hotel, "Aucun processeur disponible"))
        
        # Traiter les h√¥tels sans URLs (r√©sultats vides)
        for hotel in hotels_without_urls:
            results.append(self._create_no_url_result(hotel))
        
        # Log final
        processing_time = (datetime.now() - self.stats['processing_start']).total_seconds()
        print(f"‚úÖ Traitement termin√© en {processing_time:.1f}s")
        print(f"   üî• Firecrawl: {self.stats['firecrawl_success']}")
        print(f"   üîÑ Legacy: {self.stats['legacy_fallback']}")
        print(f"   ‚ùå √âchecs: {self.stats['total_failures']}")
        
        return results
    
    async def _process_with_firecrawl(self, hotels_data: List[Dict]) -> List[Dict[str, Any]]:
        """Traite avec Firecrawl"""
        
        try:
            firecrawl_config = FirecrawlConfig(
                api_key=self.config.firecrawl_api_key,
                rate_limit_requests_per_minute=100,  # Plan payant
                rate_limit_wait_seconds=1,  # S√©curit√© 1s
                timeout=self.config.timeout
            )
            
            async with FirecrawlExtractor(firecrawl_config) as extractor:
                results = await extractor.extract_hotels_batch(hotels_data)
            
            # üî• FIRECRAWL ONLY - Pas de fallback Legacy
            processed_results = []
            for result in results:
                if result['success']:
                    self.stats['firecrawl_success'] += 1
                else:
                    self.stats['total_failures'] += 1
                processed_results.append(self._format_firecrawl_result(result))
            
            return processed_results
            
        except Exception as e:
            print(f"‚ùå Erreur Firecrawl globale: {e}")
            # üî• PAS DE FALLBACK - Retourner des √©checs
            return [self._create_failure_result(hotel, str(e)) for hotel in hotels_data]
    
    async def _process_with_legacy(self, hotels_data: List[Dict]) -> List[Dict[str, Any]]:
        """Traite avec Legacy system (temporaire)"""
        
        print("üîÑ Traitement Legacy temporaire...")
        results = []
        
        for hotel in hotels_data:
            try:
                # Extraction basic legacy
                result = {
                    'success': True,
                    'hotel_name': hotel['name'],
                    'hotel_address': hotel.get('address', ''),
                    'website_data': self._create_empty_hotel_data(),
                    'metadata': {
                        'url': hotel.get('website_url', ''),
                        'extraction_method': 'legacy_placeholder',
                        'processing_date': datetime.now().isoformat()
                    },
                    'error': None
                }
                results.append(result)
                self.stats['legacy_fallback'] += 1
                
            except Exception as e:
                results.append(self._create_failure_result(hotel, str(e)))
                self.stats['total_failures'] += 1
        
        return results
    
    def _normalize_hotel_data(self, hotels_data: List[Dict]) -> List[Dict]:
        """Normalise les donn√©es d'h√¥tels pour traitement uniforme"""
        
        normalized = []
        for hotel in hotels_data:
            normalized_hotel = {
                'name': hotel.get('name', hotel.get('hotel_name', 'Hotel_Unknown')),
                'address': hotel.get('address', hotel.get('hotel_address', '')),
                'website_url': hotel.get('website_url', hotel.get('url', ''))
            }
            
            # Validation URL
            website_url = normalized_hotel['website_url']
            if website_url and not website_url.startswith(('http://', 'https://')):
                if '.' in website_url:  # Semble √™tre un domaine
                    normalized_hotel['website_url'] = f"https://{website_url}"
                else:
                    normalized_hotel['website_url'] = ''  # URL invalide
            
            normalized.append(normalized_hotel)
        
        return normalized
    
    def _format_firecrawl_result(self, firecrawl_result: Dict) -> Dict[str, Any]:
        """Formate le r√©sultat Firecrawl pour compatibilit√© avec le syst√®me existant"""
        
        if not firecrawl_result['success']:
            return firecrawl_result
        
        # Mapper les donn√©es Firecrawl vers le format attendu par le consolidator
        website_data = firecrawl_result.get('website_data', {})
        
        # Format compatible avec data_consolidator.py
        formatted_result = {
            'success': True,
            'hotel_name': firecrawl_result['hotel_name'],
            'hotel_address': firecrawl_result['hotel_address'],
            'website_data': website_data,  # D√©j√† au bon format
            'metadata': firecrawl_result.get('metadata', {}),
            'error': None
        }
        
        return formatted_result
    
    def _create_empty_hotel_data(self) -> Dict[str, Any]:
        """Cr√©e un jeu de donn√©es h√¥tel vide pour Firecrawl"""
        
        # üî• Structure vide compatible Firecrawl
        return {
            'capacite_max': None,
            'nombre_chambre': None,
            'nombre_etoile': None,
            'pr_parking': None,
            'pr_restaurant': None,
            'pr_wifi': None,
            'summary': '',
            'hotel_phone': None,
            'hotel_email': None,
            'meeting_rooms_available': None
        }
    
    def _create_no_url_result(self, hotel: Dict) -> Dict[str, Any]:
        """Cr√©e un r√©sultat pour un h√¥tel sans URL"""
        
        return {
            'success': False,
            'hotel_name': hotel['name'],
            'hotel_address': hotel.get('address', ''),
            'website_data': self._create_empty_hotel_data(),
            'metadata': {
                'url': '',
                'extraction_method': 'none',
                'processing_date': datetime.now().isoformat()
            },
            'error': 'Aucune URL de site web fournie'
        }
    
    def _create_failure_result(self, hotel: Dict, error_message: str) -> Dict[str, Any]:
        """Cr√©e un r√©sultat d'√©chec"""
        
        return {
            'success': False,
            'hotel_name': hotel['name'],
            'hotel_address': hotel.get('address', ''),
            'website_data': self._create_empty_hotel_data(),
            'metadata': {
                'url': hotel.get('website_url', ''),
                'extraction_method': 'failed',
                'processing_date': datetime.now().isoformat()
            },
            'error': error_message
        }


# Fonction d'usage pratique pour compatibilit√©
async def process_hotels_websites(hotels_data: List[Dict[str, Any]], 
                                 config: WebsiteProcessorConfig = None) -> List[Dict[str, Any]]:
    """Fonction utilitaire pour traiter des sites web d'h√¥tels
    
    Args:
        hotels_data: Liste de donn√©es h√¥tels avec name, address, website_url
        config: Configuration optionnelle
        
    Returns:
        Liste des r√©sultats de traitement
    """
    
    processor = WebsiteProcessor(config)
    return await processor.process_hotels_websites(hotels_data)


# üî• FONCTION DE COMPATIBILIT√â SUPPRIM√âE - Firecrawl only
# Plus besoin de process_content_batch legacy