"""
Service d'extraction avec Supabase - Nouvelle architecture
Remplace la consolidation CSV par l'insertion directe en DB
"""

import streamlit as st
import asyncio
import os
import time
from datetime import datetime
from typing import Dict, List, Any

import sys
from pathlib import Path

# Ajouter les modules au path
sys.path.append(str(Path(__file__).parent.parent))

from modules.database_service import DatabaseService
from modules.parallel_processor_db import ParallelHotelProcessorDB, ParallelConfig
from modules.supabase_client import SupabaseError


class ExtractionServiceDB:
    """Service principal pour les extractions avec Supabase"""

    def __init__(self):
        try:
            self.db_service = DatabaseService()
            self.session_id = None
        except SupabaseError as e:
            st.error(f"‚ùå Erreur configuration Supabase: {e}")
            st.info("üîß V√©rifiez SUPABASE_URL et SUPABASE_KEY dans votre .env")
            raise

    def process_csv_extraction(
        self,
        df,
        extract_gmaps: bool = False,
        extract_website: bool = False
    ):
        """Traite l'extraction pour un fichier CSV avec Supabase"""
        st.subheader("üîÑ Extraction vers Supabase...")

        try:
            # Cr√©er une session d'extraction
            csv_filename = f"upload_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            self.session_id = self.db_service.create_new_session(
                csv_filename=csv_filename,
                total_hotels=len(df)
            )

            # Stocker dans l'√©tat Streamlit pour persistance
            st.session_state['last_session_id'] = self.session_id

            st.info(f"üìä Session cr√©√©e: {len(df)} h√¥tels √† traiter")

            # Pr√©parer les donn√©es
            hotels_data = []
            for _, row in df.iterrows():
                hotel_info = self._extract_hotel_info_from_row(row)
                hotels_data.append(hotel_info)

            # Utiliser le processeur parall√®le DB
            config = ParallelConfig()
            processor = ParallelHotelProcessorDB(config)

            # Interface de suivi en temps r√©el
            progress_container = st.container()
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
                stats_placeholder = st.empty()

                # Tableau temps r√©el
                realtime_placeholder = st.empty()

                # Section t√©l√©chargement CSV
                download_section = st.empty()

            # Callback de progression
            def update_progress(stats):
                # Barre de progression
                progress = stats['progress_percent'] / 100
                progress_bar.progress(progress)

                # Status text
                eta_text = f" (ETA: {stats.get('eta_seconds', 0):.0f}s)" if stats.get('eta_seconds', 0) > 0 else ""
                status_text.text(
                    f"üîÑ Batch {stats.get('batch_completed', 0)}/{stats.get('total_batches', 0)} "
                    f"| {stats['completed']}/{stats['total_hotels']} h√¥tels"
                    f" | Erreurs: {stats['errors']}{eta_text}"
                )

                # Stats d√©taill√©es
                with stats_placeholder:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Compl√©t√©s", stats['completed'])
                    with col2:
                        st.metric("Erreurs", stats['errors'])
                    with col3:
                        st.metric("Progression", f"{stats['progress_percent']:.1f}%")
                    with col4:
                        st.metric("Temps √©coul√©", f"{stats.get('elapsed_time', 0):.0f}s")

                # Tableau temps r√©el depuis Supabase
                self._update_realtime_table(realtime_placeholder)

                # Bouton de t√©l√©chargement CSV dynamique
                self._update_download_section(download_section, stats)

            # Lancer le traitement
            try:
                final_stats = asyncio.run(
                    processor.process_hotels_to_database(
                        hotels_data=hotels_data,
                        session_id=self.session_id,
                        extract_cvent=True,
                        extract_gmaps=extract_gmaps,
                        extract_website=extract_website,
                        progress_callback=update_progress
                    )
                )

                # Finalisation (sans boutons d'export)
                self._display_final_results_simple(final_stats, progress_bar, status_text)

            except Exception as e:
                st.error(f"‚ùå Erreur traitement: {e}")
                self._cleanup_failed_session()

        except Exception as e:
            st.error(f"‚ùå Erreur cr√©ation session: {e}")

    def process_single_url_extraction(
        self,
        name: str,
        address: str,
        url: str,
        extract_gmaps: bool = False,
        extract_website: bool = False
    ):
        """Traite l'extraction pour une URL unique avec Supabase"""
        st.subheader("üîÑ Extraction URL unique vers Supabase...")

        try:
            # Cr√©er une session pour l'URL unique
            session_name = f"URL_{name}_{datetime.now().strftime('%H%M%S')}"
            self.session_id = self.db_service.create_new_session(
                csv_filename=session_name,
                total_hotels=1
            )

            # Stocker dans l'√©tat Streamlit pour persistance
            st.session_state['last_session_id'] = self.session_id

            hotel_data = {
                'name': name,
                'address': address,
                'url': url
            }

            # Traiter avec le processeur DB
            config = ParallelConfig()
            processor = ParallelHotelProcessorDB(config)

            # Interface simple pour URL unique
            with st.spinner(f"Extraction de {name}..."):
                final_stats = asyncio.run(
                    processor.process_hotels_to_database(
                        hotels_data=[hotel_data],
                        session_id=self.session_id,
                        extract_cvent=True,
                        extract_gmaps=extract_gmaps,
                        extract_website=extract_website
                    )
                )

            # Affichage des r√©sultats
            if final_stats['successful'] > 0:
                st.success(f"‚úÖ Extraction r√©ussie pour {name}")
                st.info("üíæ Donn√©es sauvegard√©es dans Supabase - Consultez l'onglet Exports pour t√©l√©charger")
            else:
                st.error(f"‚ùå √âchec extraction pour {name}")

        except Exception as e:
            st.error(f"‚ùå Erreur extraction URL: {e}")

    def _extract_hotel_info_from_row(self, row) -> Dict[str, str]:
        """Extrait les informations d'h√¥tel depuis une ligne CSV"""
        def clean_value(value):
            if value is None:
                return ''
            str_value = str(value).strip()
            if str_value.lower() in ['nan', 'none', '']:
                return ''
            return str_value

        return {
            'name': clean_value(row['name']),
            'address': clean_value(row.get('adresse', '')),
            'url': clean_value(row.get('URL', ''))
        }

    def _update_realtime_table(self, placeholder):
        """Met √† jour le tableau temps r√©el depuis Supabase"""
        if not self.session_id:
            return

        try:
            # R√©cup√©rer les stats depuis Supabase
            stats = self.db_service.get_session_statistics(self.session_id)

            with placeholder.container():
                st.subheader("üìä Progression en temps r√©el")

                if stats:
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric(
                            "Total",
                            stats.get('total_hotels', 0)
                        )
                    with col2:
                        st.metric(
                            "Compl√©t√©s",
                            stats.get('completed', 0),
                            delta=f"+{stats.get('completed', 0)}"
                        )
                    with col3:
                        st.metric(
                            "En cours",
                            stats.get('processing', 0)
                        )
                    with col4:
                        st.metric(
                            "√âchecs",
                            stats.get('failed', 0),
                            delta=f"+{stats.get('failed', 0)}" if stats.get('failed', 0) > 0 else None
                        )

                    # Graphique de progression
                    total = stats.get('total_hotels', 1)
                    completed = stats.get('completed', 0)
                    failed = stats.get('failed', 0)
                    pending = stats.get('pending', 0)
                    processing = stats.get('processing', 0)

                    progress_data = {
                        'Status': ['Compl√©t√©s', '√âchecs', 'En cours', 'En attente'],
                        'Count': [completed, failed, processing, pending]
                    }

                    st.bar_chart(progress_data, x='Status', y='Count')

        except Exception as e:
            st.warning(f"Erreur mise √† jour temps r√©el: {e}")

    def _update_download_section(self, placeholder, stats):
        """Met √† jour la section de t√©l√©chargement CSV"""
        if not self.session_id:
            return

        try:
            # R√©cup√©rer les statistiques d'export
            export_stats = self.db_service.get_session_export_stats(self.session_id)

            with placeholder.container():
                st.subheader("üì• T√©l√©chargement CSV")

                # Informations sur les donn√©es disponibles
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        "H√¥tels trait√©s",
                        export_stats.get('hotels_with_data', 0),
                        delta=f"sur {export_stats.get('total_hotels', 0)}"
                    )

                with col2:
                    st.metric(
                        "Salles extraites",
                        export_stats.get('total_rooms', 0)
                    )

                with col3:
                    # Statut d'export
                    if export_stats.get('export_ready', False):
                        st.success("‚úÖ Donn√©es disponibles")
                    else:
                        st.info("‚è≥ En cours...")

                # Info sur les donn√©es disponibles
                if export_stats.get('total_rooms', 0) > 0:
                    st.info(f"üíæ {export_stats['total_rooms']} salles extraites jusqu'√† pr√©sent")
                    st.caption("üì• Consultez l'onglet **Exports** pour t√©l√©charger en continu")
                else:
                    st.info("‚ÑπÔ∏è Extraction en cours...")

                # Message d'aide
                st.caption("üí° Ce CSV contient toutes les donn√©es extraites jusqu'√† pr√©sent. Vous pouvez l'interrompre et t√©l√©charger √† tout moment.")

        except Exception as e:
            with placeholder.container():
                st.error(f"‚ùå Erreur section t√©l√©chargement: {e}")

    def _display_final_results(
        self,
        final_stats: Dict[str, Any],
        progress_bar,
        status_text
    ):
        """Affiche les r√©sultats finaux"""
        progress_bar.progress(1.0)

        if final_stats['failed'] == 0:
            status_text.success("üéâ Extraction termin√©e avec succ√®s!")
        else:
            status_text.warning(
                f"‚ö†Ô∏è Extraction termin√©e: {final_stats['failed']} √©checs"
            )

        # Affichage des statistiques finales
        st.subheader("üìä R√©sultats finaux")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Total trait√©",
                final_stats['total_hotels']
            )
        with col2:
            st.metric(
                "Succ√®s",
                final_stats['successful'],
                delta=f"{(final_stats['successful']/final_stats['total_hotels']*100):.1f}%"
            )
        with col3:
            st.metric(
                "√âchecs",
                final_stats['failed']
            )
        with col4:
            st.metric(
                "Temps total",
                f"{final_stats.get('elapsed_time', 0):.1f}s"
            )

        # Option d'export CSV depuis la DB
        self._display_export_options()

    def _display_hotel_data(self):
        """Affiche les donn√©es d'un h√¥tel depuis la DB"""
        if not self.session_id:
            return

        try:
            # Ici on pourrait r√©cup√©rer et afficher les donn√©es
            # depuis Supabase pour v√©rification
            st.info("üíæ Donn√©es sauvegard√©es dans Supabase")

            # TODO: Ajouter un aper√ßu des donn√©es ins√©r√©es
            with st.expander("üëÅÔ∏è Aper√ßu des donn√©es"):
                st.info("Fonctionnalit√© d'aper√ßu en d√©veloppement")

        except Exception as e:
            st.warning(f"Erreur affichage donn√©es: {e}")

    def _display_final_results_simple(
        self,
        final_stats: Dict[str, Any],
        progress_bar,
        status_text
    ):
        """Affiche les r√©sultats finaux sans boutons d'export"""
        progress_bar.progress(1.0)

        if final_stats['failed'] == 0:
            status_text.success("üéâ Extraction termin√©e avec succ√®s!")
        else:
            status_text.warning(
                f"‚ö†Ô∏è Extraction termin√©e: {final_stats['failed']} √©checs"
            )

        # Affichage des statistiques finales
        st.subheader("üìä R√©sultats finaux")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Total trait√©",
                final_stats['total_hotels']
            )
        with col2:
            st.metric(
                "Succ√®s",
                final_stats['successful'],
                delta=f"{(final_stats['successful']/final_stats['total_hotels']*100):.1f}%"
            )
        with col3:
            st.metric(
                "√âchecs",
                final_stats['failed']
            )
        with col4:
            st.metric(
                "Temps total",
                f"{final_stats.get('elapsed_time', 0):.1f}s"
            )

        # Message de redirection vers la page Exports
        st.success("‚úÖ Extraction termin√©e!")
        st.info("üì• Consultez l'onglet **Exports** dans la navigation pour t√©l√©charger vos CSV")

    def _cleanup_failed_session(self):
        """Nettoie une session √©chou√©e"""
        if self.session_id:
            try:
                self.db_service.finalize_session(self.session_id, success=False)
            except:
                pass